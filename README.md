# ğŸ” Recallr

**Persistent LLM chat memory, session context, and global user state for Golang.**  
Drop-in memory infrastructure for building smart, context-aware LLM apps.

---

## ğŸš€ What is Recallr?

Recallr is a lightweight, pluggable Go library that enables:

- âœ… **Session memory** â€“ track ongoing conversations
- âœ… **Chat recovery** â€“ restore full context after a session ends
- âœ… **Global user memory** â€“ build long-term user traits/preferences
- âœ… **DiceDB-backed persistence** â€“ fully local, fast, and embeddable
- âœ… **Framework-free** â€“ use with any LLM API or stack

No Python. No extra servers. Just Go.

---

## ğŸ§  Core Concepts

| Component         | Description                                                                 |
|------------------|-----------------------------------------------------------------------------|
| `SessionManager` | Manages in-session chat memory                                              |
| `ChatHistory`    | Stores and loads full chat histories per session                            |
| `UserMemory`     | Long-term memory store with user facts, traits, preferences                 |
| `PromptBuilder`  | Composes input prompts with memory, history, and current user message       |
| `LLMClient`      | Interface wrapper to plug in OpenAI, local models, or anything else         |

---

## ğŸ› ï¸ Quick Start

```
import "github.com/your-org/recallr"

llm := recallr.New(recallr.Config{
    Storage: DiceDBStore,
    LLM:     OpenAIClient,
})

response := llm.Handle("user123", "session456", "What's the weather in Berlin?")
fmt.Println(response)
```
